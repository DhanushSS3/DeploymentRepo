#!/usr/bin/env python3
"""
Test script for provider logging system.
This script tests the logging configuration, file rotation, and statistics logging.
"""

import asyncio
import time
import random
import orjson
from pathlib import Path

# Add the app directory to the path for imports
import sys
sys.path.append(str(Path(__file__).parent / 'app'))

from app.services.logging.provider_logger import (
    get_dispatcher_logger,
    get_worker_open_logger,
    get_worker_close_logger,
    get_orders_calculated_logger,
    get_provider_errors_logger,
    log_provider_stats,
    cleanup_old_logs,
    get_all_provider_loggers,
    get_log_directory
)

async def test_basic_logging():
    """Test basic logging functionality for all loggers."""
    print("üîç Testing basic logging functionality...")
    
    # Get all loggers
    dispatcher_logger = get_dispatcher_logger()
    open_logger = get_worker_open_logger()
    close_logger = get_worker_close_logger()
    calc_logger = get_orders_calculated_logger()
    error_logger = get_provider_errors_logger()
    
    # Test each logger
    loggers = [
        ("Dispatcher", dispatcher_logger),
        ("Worker Open", open_logger),
        ("Worker Close", close_logger),
        ("Orders Calculated", calc_logger),
        ("Provider Errors", error_logger)
    ]
    
    for name, logger in loggers:
        logger.info(f"[TEST] {name} logger initialized successfully")
        logger.debug(f"[TEST] {name} debug message")
        logger.warning(f"[TEST] {name} warning message")
        
    print("‚úÖ Basic logging test completed")

async def test_calculated_orders_logging():
    """Test the calculated orders JSON logging."""
    print("üîç Testing calculated orders logging...")
    
    calc_logger = get_orders_calculated_logger()
    
    # Simulate order calculation logs
    for i in range(5):
        order_calc = {
            "type": "ORDER_OPEN_CALC",
            "order_id": f"test_order_{i}",
            "user_type": "live",
            "user_id": f"user_{i}",
            "symbol": "EURUSD",
            "side": "BUY",
            "final_exec_price": 1.0950 + (i * 0.0001),
            "final_order_qty": 10000.0,
            "single_margin_usd": 100.0 + (i * 10),
            "commission_entry": 2.5,
            "half_spread": 0.00005,
            "contract_size": 100000.0,
            "provider": {
                "ord_status": "EXECUTED",
                "exec_id": f"exec_{i}",
                "avgpx": 1.0950 + (i * 0.0001),
                "cumqty": 10000.0
            }
        }
        calc_logger.info(orjson.dumps(order_calc).decode())
        
    print("‚úÖ Calculated orders logging test completed")

async def test_error_logging():
    """Test error logging functionality."""
    print("üîç Testing error logging...")
    
    error_logger = get_provider_errors_logger()
    
    # Simulate various error scenarios
    error_scenarios = [
        "[DISPATCH:ERROR] order_id=test_001 processing_time=150.25ms error=Redis connection timeout",
        "[OPEN:ERROR] order_id=test_002 processing_time=75.50ms error=Invalid margin calculation",
        "[CLOSE:ERROR] order_id=test_003 processing_time=200.00ms error=Order not found in Redis",
        "[DISPATCH:PUBLISH_FAILED] queue=open_queue order_id=test_004 error=RabbitMQ channel closed",
        "[OPEN:COMMISSION_ERROR] order_id=test_005 error=Commission rate not found"
    ]
    
    for error_msg in error_scenarios:
        error_logger.error(error_msg)
        await asyncio.sleep(0.1)  # Small delay between errors
        
    print("‚úÖ Error logging test completed")

async def test_statistics_logging():
    """Test statistics logging functionality."""
    print("üîç Testing statistics logging...")
    
    # Test dispatcher stats
    dispatcher_stats = {
        'start_time': time.time() - 3600,  # 1 hour ago
        'messages_processed': 1500,
        'messages_routed': 1485,
        'messages_dlq': 5,
        'routing_errors': 10,
        'redis_errors': 2,
        'last_message_time': time.time(),
        'uptime_seconds': 3600,
        'uptime_hours': 1.0,
        'messages_per_second': 0.42,
        'routing_success_rate': 99.0,
        'error_rate': 0.67
    }
    log_provider_stats('dispatcher', dispatcher_stats)
    
    # Test worker open stats
    open_stats = {
        'start_time': time.time() - 1800,  # 30 minutes ago
        'messages_processed': 750,
        'orders_opened': 740,
        'orders_failed': 10,
        'margin_calculations': 740,
        'commission_calculations': 740,
        'db_publishes': 740,
        'uptime_seconds': 1800,
        'uptime_hours': 0.5,
        'messages_per_second': 0.42,
        'success_rate': 98.67,
        'avg_processing_time_ms': 125.5
    }
    log_provider_stats('worker_open', open_stats)
    
    # Test worker close stats
    close_stats = {
        'start_time': time.time() - 2400,  # 40 minutes ago
        'messages_processed': 320,
        'orders_closed': 315,
        'orders_failed': 5,
        'close_calculations': 315,
        'context_enrichments': 50,
        'db_publishes': 315,
        'finalize_retries': 8,
        'uptime_seconds': 2400,
        'uptime_hours': 0.67,
        'messages_per_second': 0.13,
        'success_rate': 98.44,
        'avg_processing_time_ms': 89.2
    }
    log_provider_stats('worker_close', close_stats)
    
    print("‚úÖ Statistics logging test completed")

async def test_high_volume_logging():
    """Test high volume logging to trigger rotation."""
    print("üîç Testing high volume logging (this may take a moment)...")
    
    dispatcher_logger = get_dispatcher_logger()
    
    # Generate a large number of log entries to test rotation
    for i in range(1000):
        # Simulate realistic dispatcher log entries
        order_id = f"order_{random.randint(10000, 99999)}"
        redis_status = random.choice(["OPEN", "PENDING", "CLOSED", "STOPLOSS"])
        ord_status = random.choice(["EXECUTED", "PENDING", "REJECTED"])
        target_queue = random.choice(["open_queue", "close_queue", "pending_queue"])
        processing_time = random.uniform(10.0, 500.0)
        
        if i % 100 == 0:
            # Occasional DLQ message
            dispatcher_logger.warning(
                f"[DISPATCH:DLQ] order_id={order_id} reason=unmapped_routing_state redis_status={redis_status} ord_status={ord_status}"
            )
        else:
            # Normal success message
            dispatcher_logger.info(
                f"[DISPATCH:SUCCESS] order_id={order_id} redis_status={redis_status} ord_status={ord_status} target_queue={target_queue} processing_time={processing_time:.2f}ms"
            )
            
        if i % 100 == 0:
            print(f"  Generated {i+1}/1000 log entries...")
            
    print("‚úÖ High volume logging test completed")

async def test_log_directory_structure():
    """Test and display the log directory structure."""
    print("üîç Testing log directory structure...")
    
    log_dir = get_log_directory()
    print(f"üìÅ Log directory: {log_dir}")
    
    if log_dir.exists():
        print("üìã Log files found:")
        for log_file in sorted(log_dir.glob("*.log*")):
            size_mb = log_file.stat().st_size / (1024 * 1024)
            print(f"  üìÑ {log_file.name} ({size_mb:.2f} MB)")
    else:
        print("‚ùå Log directory does not exist")
        
    print("‚úÖ Log directory structure test completed")

async def test_logger_health_check():
    """Test logger health check functionality."""
    print("üîç Testing logger health check...")
    
    all_loggers = get_all_provider_loggers()
    
    print("üè• Logger Health Check:")
    for name, logger in all_loggers.items():
        handler_count = len(logger.handlers)
        level = logger.level
        propagate = logger.propagate
        
        print(f"  üìä {name}:")
        print(f"    - Handlers: {handler_count}")
        print(f"    - Level: {level}")
        print(f"    - Propagate: {propagate}")
        
        # Test that logger can write
        try:
            logger.info(f"[HEALTH_CHECK] {name} logger is healthy")
            print(f"    - Status: ‚úÖ Healthy")
        except Exception as e:
            print(f"    - Status: ‚ùå Error: {e}")
            
    print("‚úÖ Logger health check completed")

async def test_log_cleanup():
    """Test log cleanup functionality."""
    print("üîç Testing log cleanup functionality...")
    
    # Note: This is a dry run test - we won't actually delete files
    print("üßπ Log cleanup test (dry run):")
    print("  - This would clean up logs older than 30 days")
    print("  - In production, set AUTO_CLEANUP_LOGS=true to enable")
    print("  - Set LOG_RETENTION_DAYS to control retention period")
    
    # Just log that cleanup would run
    cleanup_logger = get_provider_errors_logger()
    cleanup_logger.info("[TEST] Log cleanup functionality verified")
    
    print("‚úÖ Log cleanup test completed")

async def main():
    """Run all logging tests."""
    print("üöÄ Starting Provider Logging System Tests")
    print("=" * 50)
    
    try:
        await test_basic_logging()
        await asyncio.sleep(0.5)
        
        await test_calculated_orders_logging()
        await asyncio.sleep(0.5)
        
        await test_error_logging()
        await asyncio.sleep(0.5)
        
        await test_statistics_logging()
        await asyncio.sleep(0.5)
        
        await test_high_volume_logging()
        await asyncio.sleep(0.5)
        
        await test_log_directory_structure()
        await asyncio.sleep(0.5)
        
        await test_logger_health_check()
        await asyncio.sleep(0.5)
        
        await test_log_cleanup()
        
        print("\n" + "=" * 50)
        print("üéâ All logging tests completed successfully!")
        print("\nüìã Summary:")
        print("  ‚úÖ Basic logging functionality")
        print("  ‚úÖ Calculated orders JSON logging")
        print("  ‚úÖ Error logging")
        print("  ‚úÖ Statistics logging")
        print("  ‚úÖ High volume logging (rotation test)")
        print("  ‚úÖ Log directory structure")
        print("  ‚úÖ Logger health check")
        print("  ‚úÖ Log cleanup functionality")
        
        print("\nüìÅ Check the logs directory for generated files:")
        log_dir = get_log_directory()
        print(f"   {log_dir}")
        
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
